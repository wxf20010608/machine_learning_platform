# type: ignore
import streamlit as st
import numpy as np
try:
    import cv2
except ImportError:
    st.error("OpenCVæœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install opencv-python")
    st.stop()
import torch
import torchvision.models as models
import torchvision.transforms as transforms
from PIL import Image
import time
import joblib
import os
from knn_classifier import KNNClassifier

def save_classifier(classifier):
    """ä¿å­˜åˆ†ç±»å™¨åˆ°æ–‡ä»¶"""
    try:
        classifier_path = os.path.join(os.path.dirname(__file__), 'knn_classifier.joblib')
        joblib.dump(classifier, classifier_path, compress=3)
        st.success("åˆ†ç±»å™¨å·²ä¿å­˜!")
    except Exception as e:
        st.error(f"ä¿å­˜åˆ†ç±»å™¨æ—¶å‡ºé”™: {str(e)}")
        st.warning("åˆ†ç±»å™¨å°†ä»…åœ¨å½“å‰ä¼šè¯ä¸­å¯ç”¨")

def main():
    st.set_page_config(page_title="KNNæ‘„åƒå¤´è¯†åˆ«", layout="wide")

    # é¡µé¢æ ‡é¢˜å’Œè¯´æ˜
    st.title("KNNæ‘„åƒå¤´å®æ—¶è¯†åˆ« (PyTorchç‰ˆ)")
    st.markdown("""
    ### ä½¿ç”¨è¯´æ˜:
    1. **æ‘„åƒå¤´é…ç½®**: 
       - è¾“å…¥ `0` ä½¿ç”¨æœ¬åœ°æ‘„åƒå¤´ï¼ˆéœ€è¦æ‘„åƒå¤´æƒé™ï¼‰
       - è¾“å…¥ç½‘ç»œæ‘„åƒå¤´URLï¼Œå¦‚ `http://192.168.1.100:8080/video`
       - æˆ–è€…ä½¿ç”¨IPæ‘„åƒå¤´åº”ç”¨æä¾›çš„URL
    2. ç‚¹å‡» **å¯åŠ¨æ‘„åƒå¤´** æŒ‰é’®å¼€å§‹æ•è·è§†é¢‘
    3. ä½¿ç”¨ä¸‹æ–¹æŒ‰é’®æ·»åŠ è®­ç»ƒæ ·æœ¬:
       - æŒ‰ **æ·»åŠ Aç±»æ ·æœ¬** å°†å½“å‰ç”»é¢æ·»åŠ åˆ°Aç±»
       - æŒ‰ **æ·»åŠ Bç±»æ ·æœ¬** å°†å½“å‰ç”»é¢æ·»åŠ åˆ°Bç±»
       - æŒ‰ **æ·»åŠ Cç±»æ ·æœ¬** å°†å½“å‰ç”»é¢æ·»åŠ åˆ°Cç±»
    4. æ·»åŠ è¶³å¤Ÿçš„æ ·æœ¬åï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨é¢„æµ‹å½“å‰ç”»é¢å±äºå“ªä¸ªç±»åˆ«
    
    **æ³¨æ„**: åœ¨Dockerå®¹å™¨ä¸­ï¼Œæœ¬åœ°æ‘„åƒå¤´å¯èƒ½æ— æ³•è®¿é—®ï¼Œå»ºè®®ä½¿ç”¨ç½‘ç»œæ‘„åƒå¤´URLã€‚
    """)

    # åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
    if 'classifier' not in st.session_state:
        classifier_path = os.path.join(os.path.dirname(__file__), 'knn_classifier.joblib')
        try:
            if os.path.exists(classifier_path):
                # å°è¯•åŠ è½½æ¨¡å‹ï¼Œå¦‚æœå¤±è´¥åˆ™åˆ›å»ºæ–°çš„
                try:
                    st.session_state.classifier = joblib.load(classifier_path)
                    st.success("æˆåŠŸåŠ è½½å·²ä¿å­˜çš„åˆ†ç±»å™¨!")
                except Exception as load_error:
                    st.warning(f"åŠ è½½å·²ä¿å­˜çš„åˆ†ç±»å™¨å¤±è´¥: {str(load_error)}")
                    st.info("æ­£åœ¨åˆ›å»ºæ–°çš„åˆ†ç±»å™¨...")
                    st.session_state.classifier = KNNClassifier()
                    # å°è¯•ä¿å­˜æ–°çš„åˆ†ç±»å™¨
                    try:
                        joblib.dump(st.session_state.classifier, classifier_path, compress=3)
                        st.success("æ–°åˆ†ç±»å™¨å·²åˆ›å»ºå¹¶ä¿å­˜!")
                    except Exception as save_error:
                        st.warning(f"ä¿å­˜æ–°åˆ†ç±»å™¨å¤±è´¥: {str(save_error)}")
            else:
                st.session_state.classifier = KNNClassifier()
                st.info("æœªæ‰¾åˆ°ä¿å­˜çš„åˆ†ç±»å™¨ï¼Œå·²åˆ›å»ºæ–°åˆ†ç±»å™¨")
                # å°è¯•ä¿å­˜æ–°çš„åˆ†ç±»å™¨
                try:
                    joblib.dump(st.session_state.classifier, classifier_path, compress=3)
                    st.success("æ–°åˆ†ç±»å™¨å·²ä¿å­˜!")
                except Exception as save_error:
                    st.warning(f"ä¿å­˜æ–°åˆ†ç±»å™¨å¤±è´¥: {str(save_error)}")
        except Exception as e:
            st.error(f"åˆå§‹åŒ–åˆ†ç±»å™¨æ—¶å‡ºé”™: {str(e)}")
            st.session_state.classifier = KNNClassifier()
            st.info("å·²åˆ›å»ºæ–°åˆ†ç±»å™¨")

    if 'model' not in st.session_state:
        try:
            with st.spinner("æ­£åœ¨åŠ è½½MobileNetæ¨¡å‹..."):
                # å°è¯•å¤šç§æ–¹å¼åŠ è½½æ¨¡å‹
                model = None
                load_method = "unknown"
                
                # ç›´æ¥ä½¿ç”¨æœªè®­ç»ƒæ¨¡å‹ï¼Œé¿å…ç½‘ç»œä¸‹è½½é—®é¢˜
                try:
                    st.info("æ­£åœ¨åŠ è½½MobileNetæ¨¡å‹ï¼ˆæœªè®­ç»ƒç‰ˆæœ¬ï¼‰...")
                    model = models.mobilenet_v2(weights=None)
                    load_method = "untrained"
                    st.success("âœ“ æ¨¡å‹åŠ è½½æˆåŠŸ!")
                    st.info("æ³¨æ„ï¼šä½¿ç”¨æœªè®­ç»ƒæ¨¡å‹ï¼Œç‰¹å¾æå–æ•ˆæœå¯èƒ½ä¸å¦‚é¢„è®­ç»ƒæ¨¡å‹ï¼Œä½†è¶³å¤Ÿç”¨äºKNNåˆ†ç±»")
                except Exception as e:
                    st.error(f"æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")
                    st.error("è¯·æ£€æŸ¥PyTorchå®‰è£…")
                    st.stop()
                
                # åˆ›å»ºç‰¹å¾æå–å™¨
                if model is not None:
                    st.session_state.model = torch.nn.Sequential(*list(model.children())[:-1])
                    st.session_state.model.eval()
                    st.session_state.model_load_method = load_method
                    st.success(f"æ¨¡å‹åˆå§‹åŒ–å®Œæˆ! (ä½¿ç”¨{load_method}æ¨¡å¼)")
                else:
                    st.error("æ¨¡å‹åˆ›å»ºå¤±è´¥")
                    st.stop()
                    
        except Exception as e:
            st.error(f"æ¨¡å‹åŠ è½½è¿‡ç¨‹ä¸­å‡ºç°æœªçŸ¥é”™è¯¯: {str(e)}")
            st.error("è¯·æ£€æŸ¥PyTorchå®‰è£…æˆ–é‡æ–°å¯åŠ¨åº”ç”¨")
            st.stop()

    # åˆå§‹åŒ–æ‘„åƒå¤´çŠ¶æ€
    if 'camera_on' not in st.session_state:
        st.session_state.camera_on = False
        st.session_state.frame = None
        
    # æ·»åŠ é¡µé¢åˆ·æ–°æ£€æµ‹
    if 'page_loaded' not in st.session_state:
        st.session_state.page_loaded = True
        # åˆå§‹åŒ–rerunæ ‡è®°
        st.session_state.rerun_triggered = False
    else:
        # é¡µé¢å·²ç»åŠ è½½è¿‡ï¼Œè¿™æ˜¯ä¸€æ¬¡åˆ·æ–°
        # åªæœ‰åœ¨érerunè§¦å‘çš„åˆ·æ–°ä¸”æ‘„åƒå¤´å·²å…³é—­çš„æƒ…å†µä¸‹æ‰é‡Šæ”¾èµ„æº
        if not hasattr(st.session_state, 'rerun_triggered') or not st.session_state.rerun_triggered:
            if not st.session_state.camera_on and 'cap' in st.session_state and st.session_state.cap is not None:
                try:
                    st.session_state.cap.release()
                    st.session_state.cap = None
                except:
                    pass
                
    # é‡ç½®æ¿€æ´»çŠ¶æ€ï¼Œä½†ä¿ç•™é¢„æµ‹ç»“æœ
    if not st.session_state.camera_on:
        st.session_state.activation = None

    # åˆ›å»ºä¸‰åˆ—å¸ƒå±€ï¼Œä¼˜åŒ–ç©ºé—´åˆ©ç”¨
    col1, col2, col3 = st.columns([3, 2, 2])

    with col1:
        # æ‘„åƒå¤´é…ç½®
        st.subheader("ğŸ“¹ æ‘„åƒå¤´æ§åˆ¶")
        camera_source = st.text_input(
            "æ‘„åƒå¤´æº (0=æœ¬åœ°æ‘„åƒå¤´, æˆ–è¾“å…¥ç½‘ç»œæ‘„åƒå¤´URL)",
            value="0",
            help="è¾“å…¥0ä½¿ç”¨æœ¬åœ°æ‘„åƒå¤´ï¼Œæˆ–è¾“å…¥ç½‘ç»œæ‘„åƒå¤´URLå¦‚: http://192.168.1.100:8080/video"
        )
        
        # æ‘„åƒå¤´æ§åˆ¶æŒ‰é’®
        button_text = "â¹ï¸ åœæ­¢æ‘„åƒå¤´" if st.session_state.camera_on else "ğŸ¥ å¯åŠ¨æ‘„åƒå¤´"
        if st.button(button_text, use_container_width=True):
            # åˆ‡æ¢æ‘„åƒå¤´çŠ¶æ€
            new_camera_state = not st.session_state.camera_on
            
            # å…ˆç¡®ä¿é‡Šæ”¾ä¹‹å‰çš„æ‘„åƒå¤´èµ„æº
            if st.session_state.cap is not None:
                try:
                    st.session_state.cap.release()
                    st.session_state.cap = None
                except Exception as e:
                    st.warning(f"é‡Šæ”¾æ‘„åƒå¤´èµ„æºæ—¶å‡ºç°è­¦å‘Š: {str(e)}")
            
            # æ›´æ–°æ‘„åƒå¤´çŠ¶æ€
            st.session_state.camera_on = new_camera_state
            
            # å¦‚æœæ˜¯æ‰“å¼€æ‘„åƒå¤´
            if st.session_state.camera_on:
                try:
                    # å°è¯•è§£ææ‘„åƒå¤´æº
                    if camera_source.isdigit():
                        # æœ¬åœ°æ‘„åƒå¤´
                        st.session_state.cap = cv2.VideoCapture(int(camera_source))  # type: ignore
                    else:
                        # ç½‘ç»œæ‘„åƒå¤´URL
                        st.session_state.cap = cv2.VideoCapture(camera_source)  # type: ignore
                    
                    # è®¾ç½®æ‘„åƒå¤´å±æ€§ï¼Œæé«˜æ€§èƒ½
                    if st.session_state.cap is not None:
                        st.session_state.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)  # type: ignore
                        st.session_state.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)  # type: ignore
                    
                    if not st.session_state.cap.isOpened():
                        st.error("æ— æ³•è®¿é—®æ‘„åƒå¤´ï¼Œè¯·æ£€æŸ¥æƒé™æˆ–è¿æ¥")
                        st.session_state.camera_on = False
                        st.session_state.cap = None
                    else:
                        st.success(f"âœ… æˆåŠŸè¿æ¥åˆ°æ‘„åƒå¤´æº: {camera_source}")
                except Exception as e:
                    st.error(f"âŒ å¯åŠ¨æ‘„åƒå¤´æ—¶å‡ºé”™: {str(e)}")
                    st.session_state.camera_on = False
                    st.session_state.cap = None
            else:
                # å…³é—­æ‘„åƒå¤´
                st.success("âœ… æ‘„åƒå¤´å·²åœæ­¢")

        # ä½¿ç”¨st.empty()ä½œä¸ºè§†é¢‘å¸§å ä½ç¬¦
        frame_placeholder = st.empty()

        # é¢„æµ‹ç»“æœæ˜¾ç¤ºåŒºåŸŸ
        prediction_placeholder = st.empty()

    with col2:
        # è®­ç»ƒæ ·æœ¬æ§åˆ¶
        st.subheader("ğŸ¯ è®­ç»ƒæ ·æœ¬")
        
        # æ·»åŠ æ ·æœ¬æŒ‰é’® - å‚ç›´æ’åˆ—ï¼Œæ›´å¤§çš„æŒ‰é’®
        if st.button("â• æ·»åŠ Aç±»æ ·æœ¬", key="add_a", use_container_width=True):
            if st.session_state.activation is not None:
                count = st.session_state.classifier.add_example(st.session_state.activation, "A")
                st.success(f"âœ… Aç±»æ ·æœ¬å·²æ·»åŠ  (æ€»æ•°: {count})")
                save_classifier(st.session_state.classifier)
            else:
                st.warning("âš ï¸ è¯·å…ˆå¯åŠ¨æ‘„åƒå¤´")
        
        if st.button("â• æ·»åŠ Bç±»æ ·æœ¬", key="add_b", use_container_width=True):
            if st.session_state.activation is not None:
                count = st.session_state.classifier.add_example(st.session_state.activation, "B")
                st.success(f"âœ… Bç±»æ ·æœ¬å·²æ·»åŠ  (æ€»æ•°: {count})")
                save_classifier(st.session_state.classifier)
            else:
                st.warning("âš ï¸ è¯·å…ˆå¯åŠ¨æ‘„åƒå¤´")
        
        if st.button("â• æ·»åŠ Cç±»æ ·æœ¬", key="add_c", use_container_width=True):
            if st.session_state.activation is not None:
                count = st.session_state.classifier.add_example(st.session_state.activation, "C")
                st.success(f"âœ… Cç±»æ ·æœ¬å·²æ·»åŠ  (æ€»æ•°: {count})")
                save_classifier(st.session_state.classifier)
            else:
                st.warning("âš ï¸ è¯·å…ˆå¯åŠ¨æ‘„åƒå¤´")

        st.markdown("---")
        
        if st.button("ğŸ—‘ï¸ æ¸…é™¤æ‰€æœ‰æ ·æœ¬", use_container_width=True):
            st.session_state.classifier = KNNClassifier()
            st.success("âœ… æ‰€æœ‰æ ·æœ¬å·²æ¸…é™¤")
            save_classifier(st.session_state.classifier)

    with col3:
        # æ ·æœ¬è®¡æ•°æ˜¾ç¤º
        st.subheader("ğŸ“Š æ ·æœ¬ç»Ÿè®¡")
        
        # ä½¿ç”¨æŒ‡ç¤ºå™¨æ˜¾ç¤ºæ ·æœ¬æ•°é‡
        a_count = len(st.session_state.classifier.examples['A'])
        b_count = len(st.session_state.classifier.examples['B'])
        c_count = len(st.session_state.classifier.examples['C'])
        
        col_a_stat, col_b_stat, col_c_stat = st.columns(3)
        with col_a_stat:
            st.metric("Aç±»", a_count)
        with col_b_stat:
            st.metric("Bç±»", b_count)
        with col_c_stat:
            st.metric("Cç±»", c_count)
            
        # æ¨¡å‹çŠ¶æ€
        st.subheader("ğŸ¤– æ¨¡å‹çŠ¶æ€")
        total_samples = sum(len(v) for v in st.session_state.classifier.examples.values())
        st.metric("æ€»æ ·æœ¬æ•°", total_samples)
        st.metric("Kå€¼", st.session_state.classifier.n_neighbors)
        
        # è®­ç»ƒçŠ¶æ€æŒ‡ç¤ºå™¨
        if st.session_state.classifier.is_trained:
            st.success("âœ… æ¨¡å‹å·²è®­ç»ƒ")
        else:
            st.warning("âš ï¸ æ¨¡å‹æœªè®­ç»ƒ")
        
        # è°ƒè¯•ä¿¡æ¯
        if hasattr(st.session_state, 'debug_info'):
            st.subheader("ğŸ” è°ƒè¯•ä¿¡æ¯")
            st.text(st.session_state.debug_info)
            
        # æ·»åŠ è¯¦ç»†çš„æ ·æœ¬ä¿¡æ¯
        st.subheader("ğŸ“‹ æ ·æœ¬è¯¦æƒ…")
        for class_name in ['A', 'B', 'C']:
            samples = st.session_state.classifier.examples[class_name]
            if samples:
                st.text(f"{class_name}ç±»æ ·æœ¬:")
                for i, sample in enumerate(samples[:3]):  # åªæ˜¾ç¤ºå‰3ä¸ªæ ·æœ¬
                    st.text(f"  æ ·æœ¬{i+1}: èŒƒå›´[{sample.min():.4f}, {sample.max():.4f}], å‡å€¼{sample.mean():.4f}")
                if len(samples) > 3:
                    st.text(f"  ... è¿˜æœ‰{len(samples)-3}ä¸ªæ ·æœ¬")

    # å›¾åƒé¢„å¤„ç†
    preprocess = transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
    ])

    # è§†é¢‘å¤„ç† - ä½¿ç”¨Streamlitçš„è‡ªåŠ¨é‡æ–°è¿è¡Œæœºåˆ¶
    if st.session_state.camera_on and st.session_state.cap is not None:
        # åˆå§‹åŒ–å¸§å¤„ç†è®¡æ•°å™¨ï¼Œç”¨äºæ§åˆ¶åˆ·æ–°ç‡
        if 'frame_counter' not in st.session_state:
            st.session_state.frame_counter = 0
        
        # è¯»å–å½“å‰å¸§ï¼Œæœ€å¤šå°è¯•3æ¬¡
        max_attempts = 3
        ret = False
        frame = None
        
        for attempt in range(max_attempts):
            if st.session_state.cap is not None:
                ret, frame = st.session_state.cap.read()
                if ret:
                    break
                time.sleep(0.1)  # çŸ­æš‚ç­‰å¾…åé‡è¯•
        
        if not ret:
            st.error("æ— æ³•è¯»å–æ‘„åƒå¤´ç”»é¢ï¼Œè¯·å°è¯•é‡æ–°å¯åŠ¨æ‘„åƒå¤´")
            # ä¸è¦è‡ªåŠ¨å…³é—­æ‘„åƒå¤´ï¼Œè®©ç”¨æˆ·å†³å®šæ˜¯å¦å…³é—­
            # åªæ˜¯æ˜¾ç¤ºé”™è¯¯ä¿¡æ¯ï¼Œä½†ä¿æŒæ‘„åƒå¤´çŠ¶æ€
            frame_placeholder.error("âš ï¸ æ‘„åƒå¤´è¿æ¥ä¸­æ–­ï¼Œè¯·ç‚¹å‡»åœæ­¢æŒ‰é’®åé‡æ–°å¯åŠ¨")
            time.sleep(0.5)
            st.rerun()  # é‡æ–°è¿è¡Œä»¥å°è¯•æ¢å¤
        else:
            # æ˜¾ç¤ºå¸§
            # å…¼å®¹ä¸åŒStreamlitç‰ˆæœ¬
            try:
                frame_placeholder.image(frame, channels="BGR", use_container_width=True)
            except TypeError:
                # æ—§ç‰ˆæœ¬ä¸æ”¯æŒuse_container_widthå‚æ•°
                frame_placeholder.image(frame, channels="BGR")
            
            # ç‰¹å¾æå–å’Œé¢„æµ‹ - æ¯3å¸§æ‰§è¡Œä¸€æ¬¡ä»¥å‡å°‘è®¡ç®—è´Ÿæ‹…
            st.session_state.frame_counter += 1
            if st.session_state.frame_counter % 3 == 0:  # æ¯3å¸§å¤„ç†ä¸€æ¬¡
                try:
                    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  # type: ignore
                    pil_image = Image.fromarray(frame_rgb)
                    input_tensor = preprocess(pil_image)
                    input_batch = input_tensor.unsqueeze(0)  # type: ignore

                    with torch.no_grad():
                        activation = st.session_state.model(input_batch)
                        activation = activation.squeeze().flatten().numpy()

                    st.session_state.activation = activation
                    st.session_state.frame = frame

                    # é¢„æµ‹
                    has_samples = any(len(v) > 0 for v in st.session_state.classifier.examples.values())
                    if has_samples:
                        try:
                            # æ·»åŠ è°ƒè¯•ä¿¡æ¯
                            st.session_state.debug_info = f"ç‰¹å¾ç»´åº¦: {activation.shape}, ç‰¹å¾èŒƒå›´: [{activation.min():.4f}, {activation.max():.4f}]"
                            
                            pred_class, confidence = st.session_state.classifier.predict_class(activation)
                            st.session_state.last_prediction = pred_class
                            st.session_state.last_confidence = confidence

                            if pred_class:
                                # æ˜¾ç¤ºé¢„æµ‹ç»“æœï¼Œä½¿ç”¨æ›´å¥½çš„UI
                                if confidence > 0.7:
                                    prediction_placeholder.success(
                                        f"ğŸ¯ **é¢„æµ‹ç»“æœ: {pred_class}ç±»** (ç½®ä¿¡åº¦: {confidence:.2f})"
                                    )
                                elif confidence > 0.4:
                                    prediction_placeholder.warning(
                                        f"âš ï¸ **é¢„æµ‹ç»“æœ: {pred_class}ç±»** (ç½®ä¿¡åº¦ä¸­ç­‰: {confidence:.2f})"
                                    )
                                else:
                                    prediction_placeholder.error(
                                        f"â“ **é¢„æµ‹ç»“æœ: {pred_class}ç±»** (ç½®ä¿¡åº¦è¾ƒä½: {confidence:.2f})"
                                    )
                            else:
                                prediction_placeholder.info("ğŸ” ç­‰å¾…é¢„æµ‹ç»“æœ...")
                        except Exception as pred_error:
                            st.error(f"é¢„æµ‹æ—¶å‡ºé”™: {str(pred_error)}")
                            st.error(f"é”™è¯¯è¯¦æƒ…: {type(pred_error).__name__}")
                except Exception as e:
                    st.error(f"å¤„ç†å¸§æ—¶å‡ºé”™: {str(e)}")
                    st.warning("è¯·æ£€æŸ¥æ¨¡å‹æ˜¯å¦æ­£ç¡®åŠ è½½")
            
            # æ·»åŠ è‡ªåŠ¨åˆ·æ–°æœºåˆ¶
            if st.session_state.camera_on:
                # æ ‡è®°è¿™æ¬¡rerunæ˜¯ç”±æ‘„åƒå¤´è§¦å‘çš„
                st.session_state.rerun_triggered = True
                time.sleep(0.03)  # æ§åˆ¶å¸§ç‡
                st.rerun()  # é‡æ–°è¿è¡Œåº”ç”¨ä»¥è·å–ä¸‹ä¸€å¸§
    else:
        frame_placeholder.info("æ‘„åƒå¤´å·²å…³é—­ï¼Œç‚¹å‡»æŒ‰é’®å¯åŠ¨")
        if st.session_state.last_prediction:
            prediction_placeholder.info(
                f"ä¸Šæ¬¡é¢„æµ‹: {st.session_state.last_prediction}ç±» (ç½®ä¿¡åº¦: {st.session_state.last_confidence:.2f})"
            )

    # ä¸è¦åœ¨è¿™é‡Œé‡Šæ”¾æ‘„åƒå¤´èµ„æºï¼Œå¦åˆ™ä¼šå¯¼è‡´è‡ªåŠ¨å…³é—­
    # èµ„æºé‡Šæ”¾åº”è¯¥åªåœ¨ç”¨æˆ·æ˜ç¡®å…³é—­æ‘„åƒå¤´æˆ–é¡µé¢çœŸæ­£å…³é—­æ—¶è¿›è¡Œ

    st.markdown("<div class='footer'>Â© 2025 æœºå™¨å­¦ä¹ ç®—æ³•å¹³å° | wangxianfu.top</div>", unsafe_allow_html=True)



if __name__ == "__main__":
    main()